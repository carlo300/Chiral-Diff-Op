\documentclass[a4paper, 10pt]{article}

% Linguistic and standard settings
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{/home/carlo/Modelli/modello} 


%%% Some new ad hoc commands %%%
\newcommand{\hg}{ \hat{g}_{\kappa} }                           % Kac-Moody affinization on g
\newcommand{\AG}{ \mathcal{A}_G }                          % A_G as initially def
\newcommand{\Dc}{ \mathcal{D}^{\mathrm{ch}}_{G, \kappa} }         % Chiral diff op
\newcommand{\Dd}{ \mathcal{D}^{\mathrm{ch}}_{G, \kappa^*} }       % Chiral diff op dual level
\DeclareMathOperator{\Zhu}{ Zhu}                             % Zhu algebra

\newcommand\norder[1]{\vcentcolon\mathrel{#1}\vcentcolon}

%%% Page Styles %%%
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\bfseries \thepage}
\fancyhead[C]{\bfseries Chiral Differential Operators}
\fancyhead[R]{\bfseries .}

\setlength{\headheight}{13.6pt}

%%% Bibliography stuff %%%

%%% Bibliography stuff %%%
\usepackage[autostyle]{csquotes}
\usepackage[style=alphabetic, backend=biber]{biblatex}
\addbibresource{bibliography.bib}

% Author and title
\author{Carlo Buccisano}
\title{Chiral Differential Operators}

\begin{document}
    \maketitle
    \begin{abstract}
        This is just a personal rewriting of some parts of \cite{ArMo:Vert}, with some backgrounds taken from \cite{agln} and \cite{Malikov2017}. Every mistake is due to me. 
    \end{abstract}
    \section{Background}
        Let $X = \Spec A$ be an affine algebraic variety over $\C$ (we will focus particularly on the case in which $X$ is an algebraic group).
        Let $\O_X$ be the structure sheaf.
        \begin{defn}
            A global section $\theta \in \End_{\C}(\O_X)(X)$ is a \emph{vector field} on $X$ if for each open $U \subset X$, the section $\theta(U) \coloneqq \restr{\theta}{U} \in \der_{\C}(\O_X(U), \O_X(U))$, i.e.\ it satisfies the Leibniz rule. Call  $\Theta(X)$ the set of vector fields on $X$.\\ 
            The \emph{tangent sheaf} $\Theta_X$ is defined by \[U \mapsto \Theta(U) \] and one can verify it is a $\O_X$-module, where one identifies $f \in \O_X$ with $\mu_f \in \End_{\C}(\O_X)$ being the multiplication by $f$.
        \end{defn}
        Compactly, $\Theta_X = \der_{\C}(\O_X)$ and one can prove it is a coherent sheaf. In-fact, if \[A = \C[x_1, \dots, x_n]/(f_1, \dots, f_r),\] then it is well known \[\der_{\C}(A, A) \simeq \Hom_A(\Omega_{A/\C}^1, A), \qquad \Omega_{A/\C}^1 = \frac{\bigoplus_{i=0}^n Adx_i}{(df_1, \dots, df_r)} \] so that we see $\der_{\C}(A)$ is finitely generated as an $A$-module.

        Let's now talk about cotangent sheaf. One local construction of $\Omega_{A/\C}^1$ is given by considering the $A$-module $I/I^2$ where $I$ is the kernel of the multiplication map $\mu\colon A \otimes_{\C} A \to A$, and one can prove it is generated by elements $df = f \otimes 1 - 1 \otimes f \mod I^2$.
        Globalizing this construction we obtain the following.
        \begin{defn}
            The \emph{cotangent sheaf} of $X$ is defined by \[\Omega^1_X \coloneqq \delta^{-1}(\mathcal{I}/\mathcal{I}^2) \] where $\delta\colon X \to X \times X$ is the diagonal embedding and $\mathcal{I}$ is the ideal sheaf of $\delta(X)$ in $X \times X$ ($X$ is affine so automatically separated, i.e.\ $\delta$ is a closed immersion). 
            Sections of $\Omega^1_X$ are called \emph{differential forms}.
        \end{defn}
        The cotanget sheaf is an $\O_X$-module in a natural way and it has a natural derivation $d\colon \O_X \to \Omega^1_X$ given by $df = f \otimes 1 - 1 \otimes f \mod \delta^{-1}(\mathcal{I}^2)$.
        Analogue to the affine case, we have 
        \begin{lemma}
            As an $\O_X$-module, $\Omega_X^1$ is generated by $df$, for $f \in \O_X$. 
        \end{lemma}
        And, of course, the same universal property holds.
        \begin{prop}
            We have an isomorphism in $\O_X-Mod$: \[\calHom_{\O_X}(\Omega^1_X, \O_X) \cong \Theta_X. \]
        \end{prop}
        We have an analogue situation of what happens in a manifold with charts, where we can always choose a local neighborhood trivializing the tangent bundle.
        \begin{thm}
            Let $X$ be smooth. For each $x \in X$ there exists an affine open neighborhood $V \ni x$, regular functions $x_i \in \O_X(V)$ and verctor fields $\partial_i \in \Theta_X(V)$ satisfying \[[\partial_i, \partial_j] = 0, \quad \partial_i(x_j) = \delta_{i,j}, \qquad \Theta_V = \bigoplus_i \O_V\partial_i. \] Moreover one can choose $x_1, \dots, x_n$ so that they generate the maximal ideal $\fm_x$ of the local ring $\O_{X,x}$.
        \end{thm}
        \begin{proof}
            By assumption the local ring $\O_{X, x}$ is regular, so there exist $n = \dim X$ functions $x_1, \dots, x_n$ generating the ideal $\fm_x$ (use definition of regular local ring and Nakayama's lemma). Then $dx_1, \dots, dx_n$ is a basis of the free $\O_{X,x}$-module $\Omega^1_{X, x} \simeq \Omega^1_{\O_{X, x}}$. This is a well-known result: since $\O_{X, x}$ is a finitely generated local $\C$-algebra, whose residue field is $\C$ (Nullstellensatz), then we have $\fm_x/\fm_x^2 \cong \C \otimes_{\O_{X, x}} \Omega^1_{X, x}$ and, using again Nakayama, we get what we claimed.

            Thus we can find an affine open neighborhood $V$ of $x$ such that $\Omega^1(V)$ is a free $\O_X(V)$-module with basis $dx_1, \dots, dx_n$. If we define $\partial_1, \dots, \partial_n \in \Theta_X(V)$ as the dual basis, we get $\partial_i(x_j) = \delta_{i, j}$. To obtain the desired commutation relations, write \[[\partial_i, \partial_j] = \sum_{i=1}^n g_{i,j}^l\partial_l \in \O_X(V) \] and observe that $g_{i,j}^l = [\partial_i, \partial_j]x_l = \partial_i\partial_j x_l - \partial_j\partial_i x_l = 0$.
        \end{proof}
        The set $\{x_i, \partial_i \mid 1 \leq 1 \leq n\}$ over an affine open neighborhood of $x$, satisfying the above conditions, is called a \emph{local coordinate system}.
        
        \subsection{Differential Operators}
            Let's now define a sheaf $\Dcal_X$ on $X$ as the sheaf of $\C$-subalgebras of $\mathcal{E}nd_{\C}(\O_X)$ generated by $\O_X$ (embedded, as before, as left multiplications) and $\Theta_X$.
            \begin{defn}
                The sheaf $\Dcal_X$ is called the \emph{sheaf of differential operators} on $X$. The algebra $\Dcal_X(X)$ is called the \emph{algebra of differential operators} on $X$.
            \end{defn}
            \begin{remark*}
                For now we should think only about $\Dcal_A$ for $A$ a commutative $\C$-algebra. We will see later that this definition, for finitely generated $\C$-algebras, behaves well with localization, hence it gives rise to a sheaf.
            \end{remark*}
            Observe that, on a trivializing neighborhood $U$ of $x$, we have \[[\partial, f] = \partial(f) \in \O_X(U) \qquad \forall f \in \O_X(U), \,\partial \in \Theta_X(U) \] so that we have \[\Dcal(U) = \bigoplus_{\alpha \in \N^n} \O_U \partial^{\alpha}, \qquad \partial^{\alpha} \coloneqq \partial_1^{\alpha_1}\dots\partial_n^{\alpha_n}. \]
            We have an obvious order filtration, which we can define locally by \[F_l\Dcal_U = \sum_{\abs{\alpha} \leq l} \O_U\partial^{\alpha} \] and then glue globally just by requiring all restrictions to trivial neighborhood to be in the corresponding degree. There is, though, a more natural way to define it: \[F_k\Dcal_X = \left\{\theta \in \mathcal{E}nd(\O_X) \mid [f_{k+1}, \dots, [f_2, [f_1, \theta]] \dots ] = 0 \quad \forall f_1, \dots, f_{k+1} \in \O_X \right\}. \] It is clear that $F_0\Dcal_X = \O_X$ and we have the split short exact sequence 
            \begin{diag}
                0 \ar[r] & \O_X \ar[r] & F_1\Dcal_X \ar[r] & \Theta_X \ar[r] & 0
            \end{diag}
            where $\O_X$ is embedded as multiplication, the map $F_1\Dcal_X \to \Theta_X$ is given by $P \mapsto [P, -]$. 
            Here are some basic properties of differential operators.
            \begin{prop}
                \begin{enumerate}[label=(\roman*)]
                    \item $F_{\bullet}\Dcal_X$ is an increasing filtration of $\Dcal_X$ such that $\Dcal_X = \bigcup_{l \geq 0} F_l\Dcal_X$ and each $F_l\Dcal_X$ is locally a free $\O_X$-module.
                    \item $F_0\Dcal_X = \O_X$ and $F_l\Dcal_X \circ F_m\Dcal_X \subseteq F_{l+m}\Dcal_X$.
                    \item $[F_l\Dcal_X, F_m\Dcal_X] \subseteq F_{l+m-1}\Dcal_X$.
                \end{enumerate}
            \end{prop}
            Observe that a corollary of this proposition is that the graded algebra \[\gr \Dcal_X = \bigoplus_{l \geq 0} F_l\Dcal_X/F_{l-1}\Dcal_X \] is commutative. Assume now $A = \O_X(X)$ is smooth, in the sense that $\Omega^1_A$ is a finitely generated free $A$-module. 
            \begin{prop}
                There is a (sheaf of) algebra isomorphism \[\gr\Dcal_X \stackrel{\sim}{\to} \Sym \Theta_X \cong \pi_*\O_{T^*X} \] where $\Sym \Theta_A$ is the symmetric algebra on $\Theta_A$. Moreover, it is also a Poisson algebra isomorphism.
            \end{prop}
            \begin{proof}
                See \cite[p.75]{Malikov2017}.
            \end{proof}
        \subsection{Derivations and differential forms on a group}
            Now we focus on the case $X = G$, for $G$ an affine algebraic group. Its Lie algebra $\fg$ can be defined in a lot of equivalent ways, for example as the $T_eG$ (tangent space at the identity element).
            We prefer, though, to define it in another way.
            \begin{defn}
                \label{defn:left_inv}
                The Lie algebra of $G$ is the Lie algebra of \emph{left invariant vector fields} on $G$, that is, \[\fg = \Lie(G) \coloneqq \left\{ \theta \in \Theta(G) \mid \Delta \circ \theta = (1 \otimes \theta) \circ \Delta \right\} \] where $\Delta\colon \O(G) \to \O(G) \otimes \O(G)$ is the comultiplication and $1\colon \O(G) \to \C$ is the co-unit (recall that any affine algebraic group is a Hopf algebra).
            \end{defn}
            Let's try to unfold this definition: a vector field $\theta \in \der_{\C}(\O(G))$ is in $\fg$ if and only if, for every $g \in G$, $[\lambda_g, \theta] = 0$ as endomorphism of $\O(G)$, where $\lambda_g$ corresponds to the action of $g$ (acting by left multiplication on $G$) on $\O(G)$, i.e.\ $\lambda_g(f) = f(g \cdot -)$. One way to see this is to consider the map $\phi\colon G \to G$ (so that $\theta = - \circ \phi$) and the multiplication $\mu\colon G \times G \to G$. The condition on $\theta$ translates to \[\phi(g_1 \cdot g_2) = g_1 \cdot \phi(g_2) \] and, using now $\theta = -\circ \phi$, one obtains that for every $f \in \O(G)$ and $y \in G$ we have \[\lambda_g\theta(f)(y) = \theta(f)(gy) = \theta(f(gy)) = \theta\lambda_g(f)(y). \] 

            As the above reasoning suggests, the only ``important'' information is the value at the identity $e$, as formalized by the following lemma.
            \begin{lemma}
                We have an isomorphism of Lie algebras \[\fg = \Lie(G) \to T_eG \stackrel{\mathrm{def}}{=} \der_{\C}(\O(G), \C), \qquad \theta \mapsto \epsilon \circ \theta \] where $\epsilon\colon \O(G) \to \C$ is the co-unit.
            \end{lemma}
            \begin{proof}
                The map is clearly well-defined. Its inverse is given by $\delta \mapsto (\id \otimes \delta) \circ \Delta$.
            \end{proof}

            We have a dual definition of \emph{right invariant vector fields}, requiring simply the symmetric condition $\Delta \circ \theta = (\theta \otimes 1) \circ \Delta$ for $\theta \in \der_{\C}(\O(G))$. As before, this concretely means that $\theta$ commutes with all $\rho_g$ for $g \in G$, the contragradient action induced by the right multiplication $(g, x) \mapsto xg$ on $G$ (i.e.\ $\rho_g(f) = f(- \cdot g)$). The proof is exactly as before, just by observing that this condition translates to $\phi(g_1g_2) = \phi(g_1)g_2$. Also observe that this latter condition does not give us automatically commutativity with $\lambda_g$, as well as the former doesn't give commutativity with the $\rho_g$, so there is a real distinction among left and right invariant vector fields, although they are both determined by just their value at the identity $e$ (indeed, what changes is ``how'' they are determined). They are canonically isomorphic though, so given $x \in T_eG$ we write $x_L$ (resp.\ $x_R$) to mean the corresponding left (resp.\ right) invariant vector field.

            Sometimes using the definition of $\fg$ as derivation of $\O(G)$ at $e$ can be useful, so let's state the following, which is a more concrete reformulation of the above. Let's consider left and right translations 
            \begin{gather*}
                \lambda_g\colon G \to G,\quad x \mapsto gx \leadsto \lambda_g^*\colon \O(G) \to \O(G), \quad f \mapsto f \circ \lambda_g (x \mapsto f(gx)), \\
                \rho_g\colon G \to G, \quad x \mapsto xg \leadsto \rho_g^*\colon \O(G) \to \O(G), \quad f \mapsto f \circ \rho_g (x \mapsto f(xg)).
            \end{gather*}
            We have
            \begin{lemma}
                Let $x \in \der_{\C}(\O(G), \C)$ an element of $T_eG$. Then the corresponding left and right invariant vector fields are given by \[x_L(f)(g) = x(\lambda_g^*f) = x(f(g \cdot -)), \qquad x_R(f)(g) = x(\rho_x^*f) = x(f(- \cdot g))  \] where $f \in \O(G)$, $g \in G$.
            \end{lemma}

            We can prove that left invariant and right invariant vector fields commute, as the commutation between $\lambda$ and $\rho$ suggests.

            \begin{lemma}
                \label{lemma:commutation}
                Given $x, y \in \fg$ we have \[[x_L, y_R] = 0 \in \der_{\C}(\O(G)). \]
            \end{lemma}
            \begin{proof}
                This is classical in Lie groups.
                One algebraic way to prove is to use \cref{defn:left_inv} stating that we have \[\Delta \circ x_L = (\id \otimes x_L) \circ \Delta, \qquad \Delta \circ y_R = (y_R \otimes \id) \circ \Delta. \] Then let's consider 
                \begin{gather*}
                    \Delta \circ x_L \circ y_R = (\id \otimes x_L) \circ \Delta \circ y_R = (\id \otimes x_L) \circ (\id \otimes y_R) \circ \Delta = (y_R \otimes x_L) \circ \Delta = \\
                    = (y_R \otimes \id) \circ (\id \otimes x_L) \circ \Delta = (y_R \otimes \id) \circ \Delta \circ x_L = \Delta \circ y_R \circ x_L
                \end{gather*}
                which basically says $\Delta \circ [x_L, y_R] = 0$. Composing with the map $\epsilon \otimes \id\colon \O(G) \otimes \O(G) \to \O(G)$ and using Hopf algebra axioms we can conclude.
            \end{proof}
            We also have 
            \begin{lemma}
                \label{lemma:antipode}
                Given $x, y \in \fg$, and $S\colon \O(G) \to \O(G)$ the antipode map, we have \[x_R \circ S = S \circ x_L.\]
            \end{lemma}
            \begin{proof}
                Given $f \in \O(G), g \in G$ observe that \[x_R(S(f))(g) = x(\rho_g^*S(f)) = x(f \circ \iota \circ \rho_g) = x(f \circ \lambda_{g^{-1}} \circ \iota) = S(x(\lambda_{g^{-1}}^*f)) = (Sx_L(f))(g) \] where $\iota\colon G \to G$ is the inverse map, so that $S = - \circ \iota$.
            \end{proof}

            Recall also that any affine algebraic linear group is smooth (as a scheme) and it has trivial tangent and cotangent bundles, i.e.\ \[TG \cong G \times T_eG \cong G \times \fg, \qquad T^*G \cong G \times \fg^*. \]
            \begin{lemma}
                The embedding $\fg \hookrightarrow \der_{\C}(\O(G))$ given by $x \mapsto x_L$ induces an isomorphism in $\O(G)-Mod$ \[\O(G) \otimes_{\C} \fg \stackrel{\sim}{\longrightarrow} \der_{\C}(\O(G)). \]
            \end{lemma}
            \begin{proof}
                Both sides are free $\O(G)$-modules of rank equal to $\dim_{\C} \fg = \dim G$ since $G$ is smooth. 
            \end{proof}
            We have the canonical $\O(G)$-bilinear pairing \[\langle,\rangle\colon \der_{\C}(\O(G)) \times \Omega^1(G) \to \O(G). \] Fix a $\C$-basis of $\fg$ given by $(x^1, \dots, x^d)$ (corresponding hence to an $\O(G)$-basis of $\der_{\C}(\O(G))$) and let $(\omega^1, \dots, \omega^d)$ be the dual $\O(G)$-basis of $\Omega^1(G)$. Let's introduce the structure coefficients writing \[[x^i, x^j] = \sum_p c_p^{i,j}x^p,\qquad \text{for $i,j=1,\dots,d$} \] with $c_p^{i,j} \in \C$.
            Having embedded $\fg$ into $\der_{\C}(\O(G))$ as left-invariant vector fields, we can consider also the dual embedding and write \[x^i_R = \sum_p f^{i,p}x^p, \qquad \text{for $i=1,\dots,d$} \] for some invertible (the $x^i_R$ are also a basis) matrix $(f^{i,p})_{1 \leq i, p \leq d}$ with coefficients in $\O(G)$ (observe that by $x^i$ we mean the corresponding left-invariant vector field $x^i_L$ in $\der_{\C}(\O(G))$).
            \begin{lemma}
                \label{lemma:B2}
                We have the following identities:
                \begin{enumerate}[label=(\roman*)]
                    \item For all $i, j, s = 1, \dots, d$, \[x^i_Lf^{j,s} + \sum_p c_s^{i,p}f^{j,p} = 0. \]
                    \item For all $i, j, s = 1, \dots, d$, \[\sum_p f^{i,p}\cdot x^p_Lf^{j,s} = \sum_q c^{i,j}_qf^{q,s}. \]
                \end{enumerate}
            \end{lemma}
            \begin{proof}
                The first identity is equivalent to the commutation relation \[[x^i_L, x^j_R] = 0 \] for all $i, j$ (just substitute the expression of $x^j_R$ and then put to zero every component multiplying the base elements $x_s$).

                To prove the second, let's write the relation \[[x^i_R, x^j_R] = [x^i, x^j]_R \] which says nothing else than that also $(-)_R$ is a Lie algebra morphism (same reasoning of left one). Using coordinates we have \[[x^i_R, x^j_R] = \sum_s [x^i_R, f^{j,s}x^s] = \sum_s (x^i_Rf^{j,s})x^s = \sum_{s,p} f^{i,p}(x^p_Lf^{j,s})x^s \] by the previous commutation relation. Plugging it back, we obtain the searched identities (as usual insulating every component).
            \end{proof}

            \begin{defn}
                The Lie algebra $\der_{\C}(\O(G))$ acts on $\Omega^1(G)$ by \emph{Lie derivative} as follows: \[\Omega^1(G) \ni (\Lie \theta).\omega\colon \theta_1 \mapsto \theta(\langle \theta_1, \omega \rangle) - \langle [\theta, \theta_1], \omega \rangle, \] where $\omega \in \Omega^1(G)$ and $\theta, \theta_1 \in \der_{\C}(\O(G))$.
            \end{defn}

            Let's now consider the case $\omega = f\partial g \in \Omega^1(G)$, $\tau \in \der_{\C}(\O(G))$ and try to give more explicit formulas. We have \[ \langle \tau, f\partial g \rangle = f\tau(g), \qquad (\Lie \tau).(f\partial g) = \tau(f)\partial g + f \partial(\tau(g))\] as one can verify with few computations.
            \begin{prop}
                \label{prop:lie_derivative}
                We have the following identities:
                \begin{enumerate}[label=(\arabic*)]
                    \item $(\Lie \tau).(f\omega) = \tau(f)\omega + f(\Lie \tau).\omega$.
                    \item $(\Lie f\tau).\omega = f(\Lie \tau).\omega + \langle \tau, \omega \rangle \partial f$.
                \end{enumerate}
            \end{prop}
            \begin{proof}
                Easy computations.
            \end{proof}
            Using the previously introduced $\O(G)$-basis $\{\omega_1, \dots, \omega_d\}$ of $\Omega^1(G)$ we can write \[(\Lie x^i).\omega^j = \sum_s \alpha^{i,j}_s\omega^s \] for $\alpha^{i,j}_s \in \C$ coefficients. As it happens in differential geometry, we will sometimes write \[(\Lie \theta).f = \theta(f) \] for $\theta \in \der_{\C}(\O(G))$ and $f \in \O(G)$ (i.e.\ the Lie derivative of a function along a vector field is exactly the corresponding directional derivative, seeing the vector field as a differential operator).
            We have another technical lemma.
            \begin{lemma}
                \label{lemma:B3}
                The following identities hold:
                \begin{enumerate}[label=(\roman*)]
                    \item For all $i, j = 1, \dots, d$,
                    \[(\Lie x^i).\omega^j = \sum_s c^{s,i}_j \omega^s. \]
                    \item For all $i, j = 1, \dots, d$,
                    \[(\Lie x^i_R).\omega^j = 0. \]
                \end{enumerate}
            \end{lemma}
            \begin{proof}
                For all $i, j, s = 1, \dots, d$ we have \[\alpha^{i,j}_s = \langle x^s, (\Lie x^i).\omega^j \rangle = x^i_L(\langle x^s, \omega^j\rangle) + \langle [x^s, x^i], \omega^j \rangle = c^{s, i}_j \] where we used the fact that $\omega^i$ is a $\O(G)$-dual basis of the $x^j$'s, and that $x^i_L(\delta_{s, j}) = 0$ being the derivation of a constant.
                This clearly implies (i).

                To prove (ii) let's observe first of all that \[\langle x^i_R, \omega^j \rangle = \sum_s \langle f^{i, s}x^s, \omega^j \rangle = f^{j, s} \in \O(G). \] To prove $(\Lie x^i_R).\omega^j = 0$ it suffices to show it is zero against the base of right-invariant vector fields $x^s_R$. We have 
                \begin{gather*}
                    \langle x^s_R, (\Lie x^i_R).\omega^j \rangle = x^i_R(\langle x^s_R, \omega^j\rangle) + \langle [x^s, x^i]_R, \omega^j \rangle = x^i_R(f^{s, j}) + \sum_p c^{s, i}_pf^{p, j} = \\
                    = \sum_k f^{i, k}x^k_L(f^{s, j}) + \sum_p c^{s, i}_pf^{p, j} = \sum_q c^{i, s}_qf^{q, j} + \sum_p c^{s, i}_pf^{p, j} = 0
                \end{gather*}
                where we used the second identity of \cref{lemma:B2} and the fact that $c^{i, j}_p = -c^{j, i}_p$.
            \end{proof}
            \begin{prop}
                The map \[\Omega^1(G) \to \Hom_{\C}(\fg, \O(G)), \qquad dg \mapsto (x \mapsto x_L(g)) \] is an isomorphism in $\O(G)-Mod$.
            \end{prop}
            \begin{proof}
                By Frobenius reciprocity, using that $\der_{\C}(\O(G)) \cong \O(G) \otimes_{\C} \fg$, we have \[\Hom_{\O(G)}(\der_{\C}(\O(G)), \O(G)) \cong \Hom_{\C}(\fg, \O(G)) \] and thus, as $\C$-vector spaces, we obtain \[\Omega^1(G) \cong \Hom_{\C}(\fg, \O(G)). \] This holds since $\Omega^1(G)$ is a free $\O(G)$-module of finite rank, hence its bi-dual is (canonically) isomorphic to itself as an $\O(G)$-module, and hence also as a $\C$-vector space.

                Let's write $\Omega^1(G) \ni \omega = \sum_i f_idg_i$ with $f_i \in \O(G)$. In this isomorphism, the element $\omega$ gets sent to the map $\tilde{\omega}\colon \fg \to \O(G)$ acting \[\fg \ni x \mapsto \sum_i f_i\cdot x_L(g_i) \in \O(G). \]
            \end{proof}
    \section{Chiral differential operators}
        \subsection{Definitions}
            Let $G$ be an affine algebraic group, $\fg = \Lie(G)$ its Lie algebra (over $\C$) and $\kappa$ be an invariant bilinear form. Let's recall the following.
            \begin{defn}
                The \emph{Kac-Moody affinization} of $\fg$ (related to $\kappa$) is \[ \hat{\fg}_{\kappa} \coloneqq \fg[t, t^{-1}] \oplus \C 1\] where the bracket is given by \[[xt^n, yt^m] = [x, y]t^{n+m} + n\delta_{n, -m}\kappa(x, y)1 \] and $1$ is central.
            \end{defn}
            Let's set \[\mathcal{A}_G \coloneqq U(\hat{\fg}_{\kappa}) \otimes_{\C} \O(\mathscr{L}G) \] where $\mathscr{L}G$ is the loop space of $G$. The algebra structure on $\mathcal{A}_G$ is such that \[U(\hat{g}_{\kappa}) \hookrightarrow \mathcal{A}_G,\qquad \O(\mathscr{L}G) \hookrightarrow \mathcal{A}_G \] are algebra embeddings (which, from now on, we'll implicitely use to identify for example $x \otimes 1$ with $x \in U(\hat{g}_{\kappa})$) and bracket \[[xt^m, f_{(n)}] = (x_Lf)_{(m+n)} \qquad x \in \fg,\, f \in \O(G),\, n, m \in \Z. \] 
            Let's define the subalgebra \[\mathcal{A}_{G, +} \coloneqq U(\fg[t] \oplus \C 1) \otimes_{\C} \O(\Loop G) \] and consider $\O(\Arc G)$ as an $\mathscr{A}_{G, +}$-module. To define this structure it suffices to say that $\O(\Loop G)$ acts by the natural surjection \[\O(\Loop G) \to \O(\Arc G), \quad f_{(n)} \mapsto \chi_{\Z_{<0}}(n) \cdot f_{(n)} \quad f \in \O(G), \] $\fg[t] \subset \fg\ser{t}$ acts by left invariant vector fields, (recall that $\Lie(\Arc G) \cong \fg\ser{t}$) and finally $1$ acts as identity. 
            We are finally ready to define our object of interest.
            \begin{defn}
                The algebra of global \emph{chiral differential operators} on $G$ is defined by \[\Dc \coloneqq \AG \otimes_{\mathcal{A}_{G, +}} \O(\Arc G). \]
            \end{defn}
            Let's immediately observe that, as $\hat{fg}$-module, we have \[\Dc \cong U(\hg) \otimes_{U(\fg[t] \oplus \C 1) } \O(\Arc G). \] Let's define two families of fields on $\Dc$:
            \[x(z) = \sum_{n \in \Z} (xt^n)z^{-n-1}, \qquad f(z) = \sum_{n \in \Z} f_{(n)}z^{-n-1} \qquad x \in \fg,\, f \in \O(G)\] where both $xt^n$ and $f_{(n)}$ are seen in $\End_{\C}(\Dc)$ by left multiplication. Observe that, thanks to the commutation relation defined on $\AG$, there can happen that the action of $f_{(n)}$ for $n \geq 0$ is non-trivial.
            \begin{prop}
                \label{prop:opes}
                The two fields above satisfy the following OPEs:
                \begin{gather*}
                    x(z)y(w) \sim \frac{[x, y](w)}{z - w} + \frac{\kappa(x, y)}{(z-w)^2}, \qquad f(z)g(w) \sim 0,\\
                    x(z)f(w) \sim \frac{(x_Lf)(w)}{z - w}
                \end{gather*}
                for any $x, y \in \fg$, $f, g \in \O(G)$.
            \end{prop} 
            \begin{proof}
                It suffices to check brackets, and then to use the ``locality'' proposition. For the first case we get 
                \begin{gather*}
                    [x(z), y(w)] = \sum_{n, m} [xt^n, yt^m]z^{-n-1}w^{-m-1} \stackrel{\textrm{def}}{=} \sum_{n, m}[x,y]t^{n+m}z^{-n-1}w^{-m-1} + \sum_n n\kappa(x, y)1z^{-n-1}w^{n-1}= \\
                    = \sum_k [x, y]t^k w^{-k-1}\cdot \left(\sum_n z^{-n-1}w^{n} \right) + \kappa(x, y)1 \cdot \sum_n nw^{n-1}z^{-n-1} = \\ = [x, y](w) \cdot \delta(z - w) + \kappa(x, y)1\cdot \partial_w\delta(z - w)
                \end{gather*}
                and thus we conclude. For the second case it is immediate since $\O(\Loop G)$ is abelian. Finally the third case is proven analogously by 
                \begin{gather*}
                    [x(z), f(w)] = \sum_{n, m}[x_{(n)}, f_{(m)}]z^{-n-1}w^{-m-1} = \sum_{n, m}(x_Lf)_{(n+m)}z^{-n-1}w^{-m-1} = \\ = \sum_k (x_Lf)_{(k)}w^{-k-1} \cdot \left(\sum_n z^{-n-1}w^n \right) = (x_Lf)(w) \cdot \delta(z - w). \qedhere
                \end{gather*}
            \end{proof}
            Let $(x^1, \dots, x^n)$ be an ordered basis of $\fg$ and let $\O(G)$ be generated by coordinates $\xi^1, \dots, \xi^r$. Using PBW theorem we see that we get a ``PBW'' basis of $\Dc$ by tensoring the respective two bases. Namely we obtain that $\Dc$ is spanned by vectors of the form \[x^{i_1}_{(n_1)}\dots x^{i_s}_{(n_r)} \otimes \xi^{j_1}_{(m_1)}\dots \xi^{j_t}_{(m_t)} \vac \] where $\vac = \overline{1 \otimes 1}$, $n_i < 0$.
            We can use Reconstruction Theorem to endow $\Dc$ with a vertex algebra structure: indeed we just declare to associate $xt^{-1}$ to field $x(z)$ for $x \in \fg$ and $f_{(-1)}$ to the field $f(z)$ for $f \in \O(G)$, since we already know they are mutually local and their coefficients span the whole space. 
            \begin{thm}
                There is a unique vertex algebra structure on $\Dc$ such that the embeddings 
                \begin{gather*}
                    \pi_L\colon V^{\kappa}(\fg) \hookrightarrow \Dc, \qquad u\vac \mapsto u \otimes 1, \\
                    j\colon \O(\Arc G) \hookrightarrow \Dc, \qquad f \mapsto 1 \otimes f
                \end{gather*} are homomorphisms of vertex algebras and \[x(z)f(w) \sim \frac{(x_Lf)(w)}{z - w}, \qquad x \in \fg,\, f \in \O(G). \]
            \end{thm}
            The vertex algebra $\Dc$ is also $\Z_{\geq 0}$-graded by setting $\deg x_{(n)} = -n$ and $\deg f_{(-1-j)} = j$, where $x \in \fg$, $f \in \O(G)$, $n < 0$ and $j \geq 0$. To declare this it suffices to ask for $x \in \fg$ (embedded through $\pi_L$) to have weight $1$ and for $f \in \O(G)$ (embedded through $j$) to have weight $0$, since then translation just adds $1$ to the weight.

            Consider now the subspace of $(\Dc)_1$ spanned by vectors $f\partial g$ with $f, g \in \O(G)$ (we are using $j$ again, this is the same as writing $f_{(-1)}g_{(-2)}$), and call it $\Omega$. Recalling that \[\O(G) \otimes_{\C} \fg \stackrel{\simeq}{\longrightarrow} \der_{\C}(\O(G)) \] we see that \[(\Dc)_1 = \Omega \oplus \der_{\C}(\O(G)) \] since they represent the only two possible ways for a vector to have weight $1$, i.e.\ being either $xt^{-1} \otimes f_{(-1)}$ (this is the explicit writing, we will just write $xf$ from now on) or $f\partial g$.
            Recall also that $\Omega^1(G)$, the space of $1$-differential forms on $G$, generated by $d\O(G)$ as $\O(G)$-module, satisfies \[\Omega^1(G) \cong \Hom_{\C}(\fg, \O(G)) \] by $df \mapsto (x \mapsto x_Lf)$.
            \begin{lemma}
                \label{lemma:3_2}
                The $\C$-linear map \[\Gamma\colon \Omega \to \Hom_{\O(G)}(\der_{\C}(\O(G)), \O(G)), \qquad f\partial g \mapsto \left( \O(G) \otimes \fg \ni h \otimes x \mapsto (hx)_{(1)}(f\partial g)\right) \] is an isomorphism of $\C$-vector spaces. Therefore $\Omega \cong \Omega^1(G)$ as $\C$-vector spaces.
            \end{lemma}
            \begin{proof}
                Observe that $hx \in \Dc$ (it can be re-written in a different order using commutation relation, but here it does not matter), so our first problem is to understand its associated field. Thanks to reconstruction theorem, and to the tautological $hx = h_{(-1)}x_{(-1)}\vac$, we obtain \[Y(hx, \zeta) =\,\, \norder{Y(h, \zeta)Y(x, \zeta)} \] so that \[(hx)_{(1)} = \sum_{n \leq -1}h_{(n)}x_{(-n)} + \sum_{n\geq 0} x_{(-n)}h_{(n)}. \] Applying this to $f\partial g = f_{(-1)}g_{(-2)}$ we see that all terms in the second series give $0$, since $h_{(n)}$ acts by zero having $n \geq 0$ (i.e.\ $h_{(n)}(1 \otimes *) = 0$). Using \[h_{(n)}x_{(-n)}(f\partial g) = h_{(n)}\cdot \left[ (x_Lf)_{(-1-n)}g_{(-2)} + f_{(-1)}(x_Lg)_{(-2-n)} \right] \] we see that the only nonzero term comes from $n=-1$, so that \[(hx)_{(1)}(f\partial g) = hf(x_Lg). \] The map $h \otimes x \mapsto (hx)_{(1)}(f\partial g)$ is thus a clear morphism of $\O(G)$-modules and so the map $\Gamma$ is well defined.
                Observe that by Frobenius reciprocity we have \[\Hom_{\O(G)}(\der_{\C}(\O(G)), \O(G)) \cong \Hom_{\C}(\fg, \O(G)) \] and, using this correspondence, the map $\Gamma(f\partial g)$ is just given by $\fg \ni x \mapsto f(x_Lg)$. This means that it suffices to prove that the map sending $\partial g$ to $(x \mapsto x_Lg)$ is an isomorphism of $\O(G)$-modules. Using \cref{lemma:B2} this is the same as saying that $\partial g \mapsto dg \in \Omega^1(G)$ is an isomorphism of $\O(G)$-modules. Finally, $\partial g = g_{(-2)}\vac$ is a regular function on $\mathscr{J}_1G \cong TG$ (tangent bundle of $G$) and it corresponds to $dg$.
            \end{proof}
            We can now consider the canonical $\O(G)$-bilinear pairing $\langle , \rangle\colon \der_{\C}(\O(G)) \times \Omega \to \O(G)$ and the action of $\der_{\C}(\O(G))$ on $\Omega$ by Lie derivative.
            \begin{lemma}
                \label{lemma:3_3}
                Let $x \in \fg$ and $\omega \in \Omega$. Then $x_{(1)}\omega = \langle x, \omega \rangle$ and $x_{(0)}\omega = (\Lie x).\omega$.
            \end{lemma}
            \begin{proof}
                The first identity holds by \cref{lemma:3_2} (put $\omega = f\partial g$ and then extend by linearity). We can use it to prove the second one; we have \[y_{(1)}((\Lie x).\omega) = x_L(y_{(1)}\omega) - [x, y]_{(1)}\omega = x_{(0)}y_{(1)}\omega - [x, y]_{(1)}\omega \] for all $y \in \fg$. Since \[y_{(1)}(x_{(0)}\omega) = x_{(0)}y_{(1)}\omega - [x, y]_{(1)}\omega \] for all $y \in \fg$, we conclude $x_{(0)}\omega = (\Lie x).\omega$.
            \end{proof}
        \section{Main results}
            \begin{thm}
                \begin{enumerate}[label=(\roman*)]
                    \item There is a vertex algebra embedding \[\pi_R\colon V^{\kappa^*}(\fg) \hookrightarrow \mathrm{Com}(V^{\kappa}(\fg), \Dc) \subset \Dc \] such that \[[\pi_R(x)_{(m)}, f_{(n)}] = (x_Rf)_{(m+n)} \qquad \text{for $f \in \O(G)$, $m, n \in \Z$,} \] where $x_R$ is the right invariant vector field corresponding to $x \in \fg$.
                    \item There is a vertex algebra isomorphism \[\Dc \cong \mathcal{D}_{G, \kappa^*}^{\mathrm{ch}} \] that sends $\O(G) \ni f$ to $S(f) \in \O(G)$, where $S\colon \O(G) \to \O(G)$ is the antipode.
                \end{enumerate}
            \end{thm}
            \begin{proof}
                For all this proof we will identify $x \in \fg$ (corresponding to $xt^{-1} \in V^{\kappa}(\fg)$) with its image in $\Dc$ through $\pi_L$.
                We will give a formula for the map $\pi_R$ and we will prove, in order, that the images commute with $V^{\kappa}(\fg)$, that it is injective and that it defines a vertex algebra homomorphism.

                Let as before $(x^1, \dots, x^d)$ be a basis of $\fg$, with $(\omega^1, \dots, \omega^d)$ the dual $\O(G)$-basis of $\Omega \cong \Omega^1(G)$. Then, we obtain that $(x^1, \dots, x^d)$ is also an $\O(G)$-basis of $\der_{\C}(\O(G))$ (identifying $x \in \fg$ with $x_L$). Thus, the corresponding right-invariant vector fields can be expressed by \[\Dc \ni x^i_R = \sum_p f^{i,p}x^p \] where $(f^{i, p})_{1 \leq i,p \leq d}$ is an invertible $\O(G)$-matrix.
                To define $\pi_R$, since it must be a morphism of vertex algebras, it suffices to define it only on the basis $x^i \cong x^it^{-1}$ of $V^{\kappa^*}(\fg)$, so let's set \[\pi_R(x^i) \coloneqq x^i_R + \sum_{q, p} \kappa^*(x^p, x^q)f^{i,p}\omega^q \in (\Dc)_1 = \der_{\C}(\O(G)) \oplus \Omega. \] To verify it commutes with all elements of $V^{\kappa}(\fg)$ it suffices to prove (classical argument using Borcherds identities) that \[v_{(n)}\pi_R(s) = 0 \qquad \forall v \in V^{\kappa}(\fg),\, s \in V^{\kappa^*}(\fg),\, n \geq 0 \] and, more specifically, we can just verify this relation for $v = x^i$ and $s=x^j$ for all $i, j$ (i.e.\ we just check it on generators, thanks to Borcherds identities).
                So our first step will be to prove 
                \begin{gather}
                    (x^i)_{(n)}\pi_R(x^j) = 0 
                \end{gather} 
                for all $i, j$ and $n \geq 0$. 
                \begin{lemma}
                    We have $(x^i)_{(n)}\pi_R(x^j)=0$ for all $n \geq 2$.
                \end{lemma}
                \begin{proof}
                    One way to convince oneself about this is to use the OPEs in \cref{prop:opes} and Wick's theorem. In this case we can do explicit computation, though, and we will do them to warm us up.
                    First thing first $(x^i)_{(n)}x^j_R = \sum_p (x^i)_{(n)}(f^{j,p}x^p)$, so let's focus on terms of this type. Observe that by Borcherds 2 (commutators identity) and by the fact that $(x^i)_{(n)}x^j = 0$ for $n \geq 2$ (OPE) we have \[(x^i)_{(n)}(f^{j,p}x^p) = [x^i_{(n)}, f^{j,p}_{(-1)}]x^p = \sum_{j \geq 0} \binom{n}{j} (x^i_{(j)}f^{j, p})_{(n-1-j)}x^p \] and using the OPE of $x(z)f(z)$ we get \[(x^i)_{(n)}(f^{j,p}x^p) = (x^i_{(0)}f^{j,p})_{(n-1)}x^p = (x^i_Lf^{j,p})_{(n-1)}x^p  \] which is zero for $n \geq 2$. 

                    The second part is just proving $(x^i)_{(n)}(f^{j, p}\omega^q) = 0$ for $n \geq 2$. Recalling that $\Omega$ is generated by $f\partial g = f_{(-1)}g_{(-2)}$ and that $x_Lg = \langle x, \omega \rangle$ for $x \in \fg$, we obtain, recalling that $\fg\ser{t}$ acts by derivation, that \[x^i_{(n)}(f^{j,p}\omega^q) = (x_Lf)_{(n-1)}\omega^q - f^{j,p}\langle x^i, \omega^q \rangle_{(n-2)} = 0 \] for $n \geq 2$. Summing these two we obtain the statement.
                \end{proof}
                By the lemma we just need to prove (1) for $n = 0, 1$.
                For the case $n = 1$ we can write:
                \begin{gather}
                    (x^i_R)_{(1)}x^j = \sum_p (f^{i,p}_{(-1)}x^p)_{(1)}x^j \stackrel{Borcherds 1}{=} \sum_p (f^{i,p}_{(-1)}x^p_{(1)}x^j + x^p_{(0)}f^{i,p}_{(0)}x^j) = \\
                    \stackrel{OPE}{=} \sum_p (f^{i,p}\kappa(x^p, x^j) - x^p_L(x^j_Lf^{i,p})).
                \end{gather}
                We used the fact that $f^{i,p}_{(0)}x^j = - x^j_{(0)}f^{i, p}$ (again skew symmetry or do the inverse OPE).
                Using \cref{lemma:B2} twice we obtain \[-x^p_L(x^j_Lf^{i, p}) = \sum_s x^p_L(c^{j,s}_pf^{i,s}) = -\sum_{s, u} c^{p,u}_sc^{j,s}_pf^{i,u} = \sum_{s, u}c^{u,p}_sc^{j,s}_pf^{i, u}. \] 
                \begin{lemma}
                    The Killing form can be expressed using structure coefficients as \[\kappa_{\fg}(x^i, x^j) = \sum_{p,q} c^{i,q}_pc^{j,p}_q  \] for any $i, j$.
                \end{lemma}
                \begin{proof}
                    Easy computation.
                \end{proof}
                We deduce that (writing explicitely and renaming the three indexes)
                \begin{gather}
                    -\sum_p x^p_L(x^j_L f^{i,p}) = \sum_u \kappa_{\fg}(x^u, x^j)f^{i,u}.
                \end{gather}
                Recalling the definition of $\kappa^*$ we get \[(x^i_R)_{(1)}x^j = -\sum_p \kappa^*(x^p, x^j)f^{i, p}. \]  Let's observe the following.
                \begin{lemma}
                    We have $(f\omega)_{(1)}(x) = x_{(1)}(f\omega)$, with obvious notation.
                \end{lemma}
                \begin{proof}
                    Observe that \[x_{(1)}(f\omega) \stackrel{derivation}{=} (x_Lf)_{(0)}\omega + f\langle x, \omega \rangle_{(-1)} = f\langle x, \omega\rangle.  \] By skew-symmetry, i.e.\ $Y(f\omega, \zeta)x = e^{\zeta T}Y(x, -\zeta)f\omega$, we have \[\sum_n (f\omega)_{(n)}x \zeta^{-n-1} = \sum_h \zeta^{-h-1} \cdot \sum_{k \geq 0} \frac{(-1)^{-k-h-1}}{k!}T^k(x_{(k+h)}(f\omega)) \] so that \[(f\omega)_{(1)}x = \sum_{k \geq 0} \frac{(-1)^{-k-2}}{k!} T^k(x_{(k+1)}(f\omega)) \stackrel{derivation}{=} x_{(1)}(f\omega) \] where only $k=0$ survives.
                \end{proof}
                By \cref{lemma:3_3}, for any $p, q$, we have 
                \begin{gather*}
                    \left(\sum_{p,q} \kappa^*(x^p, x^q)f^{i,p}\omega^q\right)_{(1)}x^j \stackrel{above}{=} \sum_{p,q}\kappa^*(x^p, x^q)x^j_{(1)}(f^{i,p}\omega^q) =\\= \sum_{p,q} \kappa^*(x^p, x^q)f^{i,p}\langle x^j, \omega^q \rangle = \sum_p \kappa^*(x^p, x^j)f^{i,p}  
                \end{gather*}
                and therefore we can conclude that $\pi_R(x^i)_{(1)}x^j = 0$. Using skew-symmetry (check proof of above lemma) we can also conclude that $x^i_{(1)}(\pi_R(x^j)) = 0$.

                Let's now focus on the case $n = 0$, i.e.\ we want to prove $(x^i)_{(0)}\pi_R(x^j) = 0$ for any $i, j$. Observe that using \cref{lemma:B2} we have \[x^i_{(0)}x^j_R = \sum_q x^i_{(0)}(f^{j,q}x^q) = \sum_q x^i_{(0)}f^{j,q}_{(-1)}x^q \stackrel{OPE}{=} \sum_q ((x^i_Lf^{j,q})_{(-1)}x^q + f^{j,q}_{(-1)}[x^i, x^q]).  \] This last sum is equal to zero because \[x^i_Lf^{j,q} = -\sum_p c^{i,p}_qf^{j,p},\qquad \sum_q f^{j,q}_{(-1)}[x^i,x^q] = \sum_{q,s} c_s^{i,q}f^{j,q}x^s \] and summing we get \[\sum_q (x^i_Lf^{j,q})_{(-1)}x^q = - \sum_{q,p} c^{i,p}_qf^ {j,p}x^q \] so that we just need to switch indexes. Thus $x^i_{(0)}x^j_R = 0$.
                On the other hand, using \cref{lemma:B2} and \cref{lemma:3_3}, we have 
                \begin{gather*}
                    \sum_{p,q} x^i_{(0)}(\kappa^*(x^p, x^q)f^{j,p}\omega^q) = \sum_{p,q} \kappa^*(x^p, x^q)((x^i_Lf^{j, p})\omega^q + f^{j,p}(\Lie x^i).\omega^q).
                \end{gather*}
                Writing $x^i_Lf^{j,p} = -\sum_s c^{i,s}_pf^{j,s}$ and $(\Lie x^i).\omega^q= -\sum_s c^{i,s}_q\omega^s$ we obtain that the above term is equal to \[-\sum_{p,q,r} \kappa^*(x^p, x^q)c^{i,r}_pf^{j,r}\omega^q + \kappa(x^p, x^q)c^{i,r}_qf^{j,p}\omega^r. \] Observing that \[\kappa^*([x^i, x^s], x^r) = \sum_k c^{i,s}_k \kappa^*(x^k, x^r) \] we can write the first part as\[ \sum_{p,q,r} \kappa^*(x^p, x^q)c^{i,r}_pf^{j,r}\omega^q = \sum_{q, r} \kappa^*([x^i, x^r], x^q)f^{j,r}\omega^q \] whereas the second part is equal to \[\sum_{p,q,r} \kappa^*(x^p, x^q)c^{i, r}_qf^{j,p}\omega^r = \sum_{p,r}\kappa^*(x^p, [x^i, x^r])f^{j,p}\omega^r \] so that, by the $\fg$-invariance of $\kappa^*$, their sum is zero. This means that \[x^i_{(0)}\left( \sum_{p,q} \kappa^*(x^p, x^q)f^{j,p}\omega^q \right) = 0 \] and therefore we can conclude that $x^i_{(0)}\pi_R(x^j) = 0$.
                In conclusion, we proved formula (1), which means that $\pi_R$ is a map from $V^{\kappa^*}(\fg)$ to $\mathrm{Com}(V^{\kappa}(\fg), \Dc)$.

                Let's now prove injectivity. This is easy since $(\Dc)_1 \cong \der_{\C}(\O(G)) \oplus \Omega$ and we can consider the projection of $\pi_R(x^i)$ onto $\der_{\C}(\O(G))$ which is equal to $x^i_R$. Since the map $\fg \ni x \mapsto x_R \in \der_{\C}(\O(G))$ is injective, we conclude that also $\pi_R$ is injective.

                We now have to prove that $\pi_R$ is indeed a vertex algebra homomorphism, which amounts to say that it respects OPE, i.e.\ that we have \[(\pi_R(x))(z)(\pi_R(y))(w) \sim \frac{1}{z-w}\pi_R([x, y])(w) + \frac{\kappa^*(x, y)}{(z-w)^2} \] for all $x, y \in \fg$. This basically means that we have to prove 
                \begin{gather*}
                    \pi_R(x)_{(n)}\pi_R(y) = 0 \qquad \forall n \geq 2,\\
                    \pi_R(x)_{(1)}\pi_R(y) = \kappa^*(x, y),\\
                    \pi_R(x)_{(0)}\pi_R(y) = \pi_R([x, y])
                \end{gather*}
                for all $x, y \in V^{\kappa^*}(\fg)$. As usual, we can just assume $x = x^i$ and $y = x^j$ to be in the basis of $\fg$. 
                \begin{prop}
                    We have $\pi_R(x^i)_{(n)}\pi_R(x^j) = 0$ for every $n \geq 2$.
                \end{prop}
                \begin{proof}
                    Expanding both sides we find terms like $(fx)_{(n)}(gy)$, $(fx)_{(n)}(g\omega)$ and $(f\omega)_{(n)}(gy)$. Let's focus on the first kind, the other are similar. We can use Reconstruction theorem to obtain the relative fields \[Y(fx, \zeta) = \norder{Y(f, \zeta)Y(x, \zeta)} \] and then Wick's theorem to get OPEs. We see that have terms like $\langle f, g\rangle = 0$, $\langle f, y \rangle = -\frac{(y_Lf)(w)}{z-w}$ and products of at most two of them, so no denominators with powers bigger than $(z-w)^2$. Thus, for $n \geq 2$ we have zero product of fields.
                \end{proof}
                
                Let's now compute \[\pi_R(x^i)_{(1)}\pi_R(x^j) = \left(x^i_R + \sum_{q,p} \kappa^*(x^p, x^q)f^{i,p}\omega^q \right)_{(1)}\left(x^j_R + \sum_{q, p}\kappa^*(x^p, x^q)f^{j,p}\omega^q \right) \] so that we see there are 4 terms. We have 
                \begin{gather*}
                    (x^i_R)_{(1)}x^j_R = \sum_{p,s}(f^{i,p}x^p)_{(1)}(f^{j,s}x^s).
                \end{gather*}
                Small computation proposition time.
                \begin{prop}
                    With obvious notation we have \[(fx)_{(1)}(gy) = fg\kappa(x, y) -fy_L(x_Lg) - gx_L(y_Lf) - (x_Lf)(y_Lg).\]  
                \end{prop}
                \begin{proof}
                    By Borcherds 1 we have \[(fx)_{(1)} = \sum_{l \geq 0} (-1)^l((-1)^1f_{(-1-l)}x_{(1+l)} + x_{(-l)}f_{(l)}). \] Observe that 
                    \begin{gather*}
                        x_{(1+l)}(gy) = g_{(-1)}x_{(1+l)}y + [x_{(1+l)}, g_{(-1)}]y = g_{(-1)}x_{(1+l)}y + (x_Lg)_{(l)}y = \\ 
                        = g \cdot x_{(1+l)}y + y(x_Lg)_{(l)} - (y_Lx_Lg)_{(l-1)} 
                    \end{gather*}
                    so the only surviving $l$ is $0$, for which we have $x_{(1)}(gy) = g\kappa(x, y) - y_L(x_Lg)$, using OPEs.
                    Instead we have 
                    \begin{gather*}
                        f_{(l)}(gy) \stackrel{abelian}{=} g_{(-1)}f_{(l)}y = gyf_{(l)} + g[f_{(l)}, y] = \\ 
                        = yg_{(-1)}f_{(l)} - (y_Lg)_{(-2)}f_{(l)} - g(y_Lf)_{(l-1)}  \stackrel{l \geq 0}{=} -g(y_Lf)_{(l-1)}
                    \end{gather*}
                    so that also here the only survival is $l=0$ with $-g(y_Lf)$.
                    Hence we have \[(fx)_{(1)}(gy) = f\cdot x_{(1)}(gy) + x_{(0)}f_{(0)}(gy) = fg\kappa(x, y) - fy_L(x_Lg) - x_{(0)}(g y_Lf) \] and recalling the action of $x_{(0)}$ we conclude.
                \end{proof}
                Using the above computation we can write \[(x^i_R)_{(1)}x^j_R = \sum_{p,s} \left(f^{i, p}f^{j,s}\kappa(x^p, x^s) - f^{i,p}x^s_L(x^p_Lf^{j,s}) - f^{j,s}x^p_L(x^s_Lf^{i,p}) - (x^p_Lf^{j,s})(x^s_Lf^{i,p})\right). \] Let's now observe that using \cref{lemma:B2}
                \begin{gather*}
                    -f^{i,p}x^s_L(x^p_Lf^{j,s}) = \sum_k c^{p,k}_sf^{i,p}(x^s_Lf^{j,k}) = -\sum_{l, k} c^{p,k}_sc^{s, l}_kf^{i,p}f^{j,l}, \\
                    -f^{j, s}x^p_L(x^s_Lf^{i,p}) = -\sum_{k,l}c^{s,k}_pc^{p,l}_kf^{j,s}f^{i,l}, \\
                    -(x^p_Lf^{j,s})(x^s_Lf^{i,p}) = -\sum_{k, l}c^{p,k}_sc^{s,l}_pf^{j,k}f^{i,l}.
                \end{gather*}
                Summing over $p$ and $s$ and summing those three terms above, using the expression of Killing form in coordinates, we obtain \[\sum_{a, b} f^{i,a}f^{j, b}\kappa_{\fg}(x^a, x^b) \] so reinserting into the initial expression we get \[(x^i_R)_{(1)}x^j_R = -\sum_{p,s} \kappa^*(x^p, x^s) f^{i,p}f^{j,s}. \]

                \begin{prop}
                    We have \[(f^{i,p}\omega^q)_{(1)}x^j_R = f^{j,q}f^{i,p}. \]
                \end{prop}
                \begin{proof}
                    Expanding $x^j_R$ we see that we just need to study terms like $(f^{i,p}\omega^q)_{(1)}(f^{j,l}x^l)$.  We will use the skew-symmetry formula \[(f^{i,p}\omega^q)_{(1)}(f^{j, l}x^l) = \sum_{k \geq 0} \frac{(-1)^{-k-2}}{k!}T^k\left((f^{j,l}x^l)_{(k+1)}(f^{i,p}\omega^q)\right). \]
                    By Borcherds 1 we have \[(f^{j,l}_{(-1)}x^l)_{(1+k)}(f^{i,p}\omega^q) = \sum_{t \geq 0} (-1)^t\left((-1)^tf^{j,l}_{(-1-t)}x^l_{(1+k+t)}(f^{i,p}\omega^q) + x^l_{(k-l)}f^{j,l}_{(t)}(f^{i,p}\omega^q) \right). \] We have \[x^l_{(1+k+t)}(f^{i,p}\omega^q) = (x^l_Lf^{i,p})_{(k+t)}\omega^q + f^{i,p}\langle x^l, \omega^q \rangle_{(k+t-1)} \] so that the first term dies since $k+t \geq 0$, as well as the second part in Borcherds identity. Then we obtain \[(f^{j, l}x^l)_{(k+1)}(f^{i,p}\omega^q) = \sum_{t \geq 0} f^{j, l}_{(-1-t)}f^{i,p}\delta^{l,q}_{(k+t-1)}. \] Then the only nonzero term is $t = -k$, so that $t = k = 0$ and we obtain \[(f^{j, l}x^l)_{(k+1)}(f^{i,p}\omega^q) = \delta_{l, q}\cdot \delta_{k, 0} \cdot f^{j,q}f^{i,p}. \] Finally, putting back into the skew symmetry, we get \[(f^{i,p}\omega^q)_{(1)}(f^{j,l}x^l) = \delta_{q, l} \cdot f^{j,q}f^{i,p} \] and summing over $l$ we conclude $(f^{i,p}\omega^q)_{(1)}x^j_R = f^{j,q}f^{i,p}$.
                \end{proof}
                Using the above proposition we obtain \[\left(\sum_{p,q} \kappa^*(x^p,x^q)f^{i,p}\omega^q\right)_{(1)}x^j_R = \sum_{p,q}\kappa^*(x^p, x^q)f^{j,q}f^{i,p}. \]
                The remaining part is \[(x^i_R)_{(1)}\left(\sum_{u, s} \kappa^*(x^s, x^u)f^{j,s}\omega^u \right) = \sum_{s,u} \kappa^*(x^s, x^u)(x^i_R)_{(1)}(f^{j,s}\omega^u). \] Expanding $x^i_R$ we see that we need to study terms like $(f^{i, l}x^l)_{(1)}(f^{j,s}\omega^u)$ and this is the usual reasoning with Borcherds 1. We have 
                \begin{gather*}
                    (f^{i,l}x^l)_{(1)}(f^{j,s}\omega^u) = \sum_{t \geq 0}(-1)^t\left((-1)^tf^{i,l}_{(-1-t)}x^l_{(1+t)}(f^{j,s}\omega^u) + x^l_{(-t)}f^{i,l}_{(t)}(f^{j,s}\omega^u) \right), \\
                    x^l_{(1+t)}(f^{j,s}\omega^u) \stackrel{derivation}{=} (x^l_Lf^ {j,s})_{(t)}\omega^u + f^{j,s}\langle x^l, \omega^u \rangle_{(t-1)} \stackrel{t \geq 0}{=} f^{j,s}\delta^{l, u}_{(t-1)}
                \end{gather*}
                so that the only surviving term is for $t = 0$ and $l = u$, in which case we obtain $f^{i,u}f^{j,s}$. Summing over $l$ we obtain \[(x^i_R)_{(1)}\left(\sum_{u,s} \kappa^*(x^s, x^u)f^{j,s}\omega^u \right) = \sum_{u,s}\kappa^*(x^s, x^u)f^{i,u}f^{j,s}. \] Finally the fourth term is zero since $\O(\Arc G)$ is commutative, i.e.\ we have \[\left(\sum_{p,q}\kappa^*(x^p, x^q)f^{i,p}\omega^q\right)_{(1)}\left(\sum_{u,s}\kappa^*(x^s, x^u)f^{j,s}\omega^u\right) = 0. \]
                Summing over these terms we obtain \[\pi_R(x^i)_{(1)}\pi_R(x^j) = \sum_{p,q} \kappa^*(x^p, x^q)f^{i,p}f^{j,q}. \] A priori this is an element of $\O(\Arc G)$, let's prove it is actually a constant. We just need to show it gets annihilated by all left-invariant vector fields, and specifically we just need to test $x^s_L$ for all $s$.
                Using identities of \cref{lemma:B2} we have 
                \begin{gather*}
                    x^s_L\left(\sum_{p,q}\kappa^*(x^p, x^q)f^{i,p}f^{j,q}\right) = \sum_{p,q}\kappa^*(x^p, x^q)\left[(x^s_Lf^{i,p})f^{j,q} + f^{i,p}(x^s_Lf^{j,q}) \right] = \\ 
                    = -\sum_{p,q, u} \kappa^*(x^p, x^q)c^{s,u}_pf^{i,u}f^{j,q} - \sum_{p,q,v} \kappa^*(x^p, x^q)c^{s,v}_qf^{j,v}f^{i,p} = \\ \stackrel{linearity}{=} -\sum_{u,q}\kappa^*([x^s, x^u], x^q)f^{i,u}f^{j,q} - \sum_{v, p}\kappa^*(x^p, [x^s, x^v])f^{j,v}f^{i,p} = \\ 
                    = \sum_{n,m}\left[\kappa^*([x^n, x^s], x^m) - \kappa^*(x^n, [x^s, x^m]) \right]f^{i,n}f^{j, m} = 0 
                \end{gather*}
                where the last equality is due to the invariance of $\kappa^*$.

                We conclude that $\sum_{p,q} \kappa^*(x^p, x^q)f^{i,p}f^{j,q}$ is constant. Observing that $f^{i,j}(e) = \delta_{i,j}$, where $e$ is the identity of $G$, we see that we have \[\pi_R(x^i)_{(1)}\pi_R(x^j) = \kappa^*(x^i, x^j) \] as we wanted.

                Let's now compute $\pi_R(x^i)_{(0)}\pi_R(x^j)$ and, as usual, let's start by expanding $\pi_R(x^j)$. Let's recall first a basic lemma of vertex algebras.
                \begin{lemma}
                    Suppose $v_{(n)}w = 0$ for each $n \geq 0$. Then $w_{(n)}v = 0$ for each $n \geq 0$.
                \end{lemma}
                \begin{proof}
                    Write \[w_{(n)}v = w_{(n)}v_{(-1)}\vac = v_{(-1)}w_{(n)}\vac + [w_{(n)}, v_{(-1)}]\vac \stackrel{n \geq 0}{=} -[v_{(-1)}, w_{(n)}]\vac\] and using Borcherds 2 \[w_{(n)}v = -\sum_{j \geq 0} (-1)^j(v_{(j)}w)_{(n-1-j)}\vac. \] This is all equal to zero since $v_{(j)}w = 0$ by assumption. 
                \end{proof}
                Let's now focus on terms like $\pi_R(x^i)_{(0)}(f^{j,q}x^q)$. We proved before that $(x^j)_{(n)}\pi_R(x^i) = 0$ for all non negative $n$ and therefore, using the lemma, we also have $\pi_R(x^i)_{(n)}x^j = 0$. Since in any vertex algebra the element $v_{(0)}$ is a ``derivation'', we have \[\pi_R(x^i)_{(0)}(f^{j,q}_{(-1)}x^q) = (\pi_R(x^i)_{(0)}f^ {j,q})_{(-1)}x^q.  \] Expanding $\pi_R(x^i)$ we need to understand terms like $(f^{i,l}x^l)_{(0)}f^{j,q}$. This is the usual Borcherds trick, for which we obtain $f^{i,l}(x^l_Lf^{j,q})$.
                Hence we have \[\pi_R(x^i)_{(0)}f^{j,q} = \sum_l f^{i,l}(x^l_Lf^{j,q}) \] and summing over $q$ we get \[\pi_R(x^i)_{(0)}x^j_R = \pi_R(x^i)_{(0)}\left(\sum_q f^{j,q}x^q\right) = \sum_{q,l} f^{i,l}(x^l_Lf^{j,q})x^q = [x^i_R, x^j_R] = [x^i, x^j]_R   \] where the last equalities come from the proof of \cref{lemma:B2}.
                We now need to study terms like $\pi_R(x^i)_{(0)}(f^{j,s}\omega^u)$, which we can already reduce to $(x^i_R)_{(0)}(f^{j,s}\omega^u)$ by the commutativity of the vertex algebra $\O(\Arc G)$. As before, using $v_{(0)}$ derivation, we have \[(x^i_R)_{(0)}(f^{j,s}\omega^u) = ((x^i_R)_{(0)}f^{j,s})_{(-1)}\omega^u + f^{j,s}(x^i_R)_{(0)}\omega^u  \] and now let's expand $x^i_R = \sum_l f^{i,l}x^l$. By Borcherds 1 we have \[(f^{i,l}x^l)_{(0)} = \sum_{t \geq 0} (-1)^t\left((-1)^tf^{i,l}_{(-1-t)}x^l_{(t)} + x^l_{(-1-t)}f^{i,l}_{(t)} \right) \] and observe that \[x^l_{(t)}f^{j,s} = (x^l_Lf^{j,s})_{(t-1)} = \delta_{t, 0} \cdot x^l_Lf^{j,s} \] so that \[(x^i_R)_{(0)}f^{j,s} = \sum_l (f^{i,l}x^l)_{(0)}f^{j,s} = \sum_l f^{i,l}(x^l_Lf^{j,s}). \] Observe now, using \cref{lemma:3_3}, that \[x^l_{(t)}\omega^u = \delta_{t, 0} \cdot (\Lie x^l).\omega^u + \delta_{t, 1} \cdot \langle x^l, \omega^u \rangle.  \] Plugging it in Borcherds 1 we get 
                \begin{gather*}
                    (x^i_R)_{(0)}\omega^u = \sum_l (f^{i, l}x^l)_{(0)}\omega^u = \sum_l f^{i,l}(\Lie x^l).\omega^u + \sum_l f^{i,l}_{(-2)}\langle x^l, \omega^u \rangle = \sum_l (\Lie f^{i,l}x^l).\omega^u = \\
                    = (\Lie(\sum_l f^{i,l}x^l)).\omega^u = (\Lie x^i_R).\omega^u = 0 
                \end{gather*}
                where the last equality come from \cref{lemma:B3} and identities on Lie derivatives in \cref{prop:lie_derivative}.

                Thus, using \cref{lemma:B2}, we can write 
                \begin{gather*}
                    (x^i_R)_{(0)}\left(\sum_{s,u} \kappa^*(x^s, x^u)f^{j,s}\omega^u \right) = \sum_{s, u} \kappa^*(x^s, x^u) \left[\sum_l f^{i,l}(x^l_Lf^{j,s})\omega^u \right] = \\
                    = \sum_{s, u, q} \kappa^*(x^s, x^u)c^{i,j}_qf^{q,s}\omega^u.
                \end{gather*} 
                Observe that we have \[\pi_R([x^i, x^j]) = \sum_q c^{i,j}_q\pi_R(x^q) = \sum_q c^{i,j}_qx^q_R + \sum_q c^{i,j}_q\left(\sum_ {s, u}\kappa^*(x^s, x^u)f^{q,s}\omega^u\right). \] Adding everything up we see that \[\pi_R(x^i)_{(0)}\pi_R(x^j) = \pi_R([x^i, x^j]) \] so that we have proved that $\pi_R$ is indeed a vertex algebra morphism.

                \textbf{Action by right invariant vector fields}\\
                Let's prove that we have the following OPE 
                \begin{gather}
                    (\pi_R(x)(z))(f(w)) \sim \frac{1}{z-w}(x_Rf)(w)
                \end{gather}
                and, as usual, assume $x = x^i$ is in the fixed basis. It is equivalent to prove that, for $n \geq 0$, we have \[\pi_R(x^i)_{(n)}f = \delta_{n, 0} \cdot (x^i_Rf).\] By the commutativity of $\O(\Arc G)$ we can write \[ (\pi_R(x^i))_{(n)}f = (x^i_R)_{(n)}f = \sum_l (f^{i,l}x^l)_{(n)}f  \] and hence we see that we just need to concentrate on terms of this kind.
                By Borcherds 1 we have \[(f^{i,l}_{(-1)}x^l)_{(n)} = \sum_{j \geq 0}\left((-1)^jf^{i,l}_{(-1-j)}x^l_{(n+j)} + x^l_{(n-1-j)}f^{i,l}_{(j)} \right) \] and we observe that \[x^l_{(n+j)}f = (x^l_Lf)_{(n+j-1)}, \qquad f^{i,l}_{(j)}f = 0. \] The first term is also zero whenever $j \geq 1 - n$ and, if $n \geq 1$, this always happens, so we conclude that \[n > 0 \implies (\pi_R(x))_{(n)}f = \sum_l (f^{i,l}x^l)_{(n)}f = 0. \] For $n = 0$ we obtain instead \[(\pi_R(x^i))_{(0)}f = \sum_l (f^{i,l}x^l)_{(0)}f = \sum_l f^{i,l}(x^l_Lf) = (x^i_Rf). \]
                This proves the OPE (5). Observe now that this implies, using Borcherds 2: \[[\pi_R(x)_{(m)}, f_{(n)}] = \sum_{j \geq 0} \binom{m}{j} (\pi_R(x)_{(j)}f)_{(m+n-j)} = (\pi_R(x)_{(0)}f)_{(m+n)} = (x_Rf)_{(m+n)}. \]


                \textbf{Second part}\\
                For the second point let's consider the vertex algebra map \[\Phi\colon \Dc \to \Dd \] whose restriction to $\O(G)$ is the antipode $S$ and whose restriction to $\fg$ is $\pi_R$. To verify it is indeed a vertex algebra homomorphism we just need to check the ``mixed'' OPE \[(\Phi(x))(z)(\Phi(f))(w) \sim \frac{1}{z-w}(\Phi(x_Lf))(w) \] for any $x \in \fg$, $f \in \O(G)$. This is true thanks to \cref{lemma:antipode} because \[\Phi(x_Lf) = S(x_Lf) = x_R(S(f)) \] and we know from the first point that \[(\pi_R(x))(z)(S(f))(w) \sim \frac{1}{z-w}( x_R(S(f)) )(w). \]
                Finally, to show that $\Phi$ is an isomorphism we can just consider the map $\Psi$ from $\Dd$ to $\mathcal{D}^{\mathrm{ch}}_{G, (\kappa^*)^*} = \Dc$ induced by antipode on $\O(G)$ and by $\pi_R(x) \mapsto \pi_L(x)$ on $V^{\kappa^*}(\fg)$. Similarly, also $\Psi$ is a vertex algebra morphism and one can verify it is inverse to $\Phi$.
            \end{proof}
        Let's do another theorem.
        \begin{thm}
            Suppose now that $G$ is connected. The vertex algebras $V^{\kappa}(\fg)$ and $V^{\kappa^*}(\fg)$ form a \emph{dual pair} in $\Dc$, i.e.\ \[V^{\kappa}(\fg) = (\Dc)^{\pi_R(\fg\ser{t})} \coloneqq \{v \in \Dc \mid \pi_R(xt^n)_{(m)}v = 0 \, \forall m \geq 0,\, x \in \fg, \},\qquad V^{\kappa^*}(\fg) = (\Dc)^{\pi_L(\fg\ser{t})}. \]
        \end{thm}
        \begin{proof}
            By the preceding theorem we already know $V^{\kappa}(\fg) \subseteq (\Dc)^{\pi_R(\fg\ser{t})}$ and, using the isomorphism of the second part, $V^{\kappa^*}(\fg) \subseteq (\Dc)^{\pi_L(\fg\ser{t})}$, so we just need to prove the inverse inclusions. Observe that, since the image of $\pi_R$ commutes with elements of $V^{\kappa}(\fg)$ (embedded in $\Dc$), we have 
            \begin{gather*}
                (\Dc)^{\pi_R(\fg\ser{t})} = \left(U(\hg) \otimes_{U(\fg[t] \oplus \C 1)} \O(\Arc G)\right)^{\pi_R(\fg\ser{t})} \cong U(\hg) \otimes_{U(\fg[t] \oplus \C 1)} \O(\Arc G)^{\pi_R(\fg\ser{t})}.
            \end{gather*}
            Since $G$ is connected we have \[\C \cong \O(\Arc G)^{\Arc G} = \O(\Arc G)^{\fg\ser{t}} = \O(\Arc G)^{\pi_R(\fg\ser{t})} \] and hence \[(\Dc)^{\pi_R(\fg\ser{t})} \cong V^{\kappa}(\fg). \] The other claim comes for free using the isomorphism $\Dc \cong \Dd$.
        \end{proof}
    \section{Other facts}
        Let's recall that for $V$ a vertex algebra we have $R_V = V/F^1V$, where $F^1V= V_{(-2)}V$. If $V$ has a PBW basis $(a^i)_i$, then one has \[F^1V = \left\{a^i_{(-n-2)}v \mid n \geq 0,\, i \in I,\, v \in V \right\}. \]
        Then the associated variety $X_V$ is defined as the reduced scheme of $\Spec R_V$.
        \begin{prop}
            We have $X_{\Dc} \cong T^*G$.
        \end{prop}
        \begin{proof}
            We already mentioned that $\Dc$ has a PBW basis so we just need to prove $R_{\Dc} \cong \C[T^*G]$. We have $T^*G \cong G \times \fg^*$ so \[\O(T^*G) \cong \O(G) \otimes \O(\fg^*) \cong \O(G) \otimes \Sym (\fg)\] where $\Sym\fg$ is the symmetric algebra of $\fg$. Observe that given a generic vector \[x^{i_1}_{(-n_1-1)}\dots x^{i_m}_{(-n_m-1)}\xi^{j_1}_{(-1-t_1)}\dots\xi^{j_r}_{(-1-t_r)} \vac \] if there exists a $n_j > 0$ then we can move, using commutators, $x^{i_j}_{(-(n_j-1)-2)}$ to the leftmost, so that this last term is in $F^1V$. Also all the other terms with commutators $[x^i_{(-n_i-1)}, x^j_{(-n_j-2)}] = [x^i, x^j]_{(-n_i-n_j-3)}$ will have ``big'' negative powers so we will be able to move to the leftmost position and prove they are in $F^1V$.
            Like this we see that the only surviving $x$ part has only $t^{-1}$ and commute, since $[xt^{-1}, yt^{-1}] = [x,y]t^{-2} \in F^1V$; thus it corresponds to $S(\fg)$. More easily, since $\O(\Arc G)$ is abelian, we can move any $f_{(-1-j)}$ with $j > 0$ to the leftmost place (before the $x$'s), and then we can use the relation $[x_{(-1)}, f_{(-1-j)}] = (x_Lf)_{(-1-(j+1))}$ to continue as before. We obtain that only the nonderived functions survive, i.e.\ the $\O(G)$ part. Thus we proved \[R_{\Dc} \cong S(\fg) \otimes \O(G). \qedhere \]
        \end{proof}
        Recall now that given $a, b \in V$ homogeneous we can define 
        \begin{gather*}
            a \circ b = \sum_{i \geq 0} \binom{\Delta_a}{i} a_{(i-2)}b,
            a * b = \sum_{i \geq 0} \binom{\Delta_a}{i} a_{(i-1)}b.
        \end{gather*}
        It is then known that $\Zhu(V) = V/V \circ V$ is an associative unital almost-commutative algebra with product $*$.
        \begin{prop}
            We have $\mathrm{Zhu}(\Dc) \cong \Dcal(G)$.
        \end{prop}
        \begin{proof}
            Since $\Dc$ has a PBW basis, we know that $R_{\Dc} \cong \gr \Zhu(\Dc)$. Since \[R_{\Dc} = S(\fg) \otimes \O(G) \cong \gr U(\fg) \otimes \O(G) \cong \gr(U(\fg) \otimes \O(G)) \cong \gr \Dcal(G) \] by PBW theorem and the isomorphism $U(\fg) \otimes \O(G) \cong \Dcal(G)$. Let's consider the map of algebras \[\Dcal(G) \to \Zhu(\Dc) = \frac{\Dc}{\Dc \circ \Dc}, \quad \fg \ni x \mapsto xt^{-1} + \Dc \circ \Dc, \quad \O(G) \ni f \mapsto f_{(-1)} + \Dc \circ \Dc.\] It is easy to verify that we have 
            \[ xt^{-1} * yt^{-1} - yt^{-1} * xt^{-1} \stackrel{formula}{=} \sum_{j \geq 0 } \binom{1-1}{j} x_{(j)}y = x_{(0)}y = [x,y]t^{-1}   \] so that our map is well defined. It clearly respects the filtration so it induces a map on the grading, which is the isomorphism of before, and thus we can conclude.
        \end{proof}

        \printbibliography
\end{document}